{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqVzrDURRdfh"
   },
   "source": [
    "Frequently Bought Toghether Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use only if on Colab and there is a _COLAB folder in your Google Drive with necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JerKv_BSSvXx",
    "outputId": "fe736be9-f69e-4adf-e0a9-a816b2cb80e9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "import os\n",
    "os.chdir(\"drive/MyDrive/_COLAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWZstf_yRdfm"
   },
   "source": [
    "Initialize graphs etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nxvzxjEORdfn"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#Nodo target\n",
    "target = 3\n",
    "\n",
    "#Grafo completo FBT\n",
    "full_graph = nx.Graph()\n",
    "\n",
    "#Grafo cluster selezionato\n",
    "clustered_graph = nx.Graph()\n",
    "\n",
    "#File di lettura\n",
    "file_name = \"Amazon0302.txt\"\n",
    "#file_name = \"grafo_esempio.txt\"\n",
    "\n",
    "#Grafo directed se True o uniderected se False\n",
    "directed = True\n",
    "\n",
    "#embedding hyperparameters\n",
    "#default = 1, 1, 10, 80\n",
    "p=1\n",
    "q=1\n",
    "num_walks=10\n",
    "walk_length=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiyIb2ksRdfq",
    "outputId": "befc1b4c-4205-4159-9cc2-de0a2df74b38"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "### LOAD GRAPH ###\n",
    "print(\"loading graph \" + file_name)\n",
    "\n",
    "if directed:\n",
    "    ##genera il grafo directed utilizzando nx.DiGraph\n",
    "    full_graph = nx.read_edgelist(file_name, nodetype=int, create_using=nx.DiGraph)\n",
    "\n",
    "else:\n",
    "    ##genera il grafo undirected utilizzando nx.Graph\n",
    "    full_graph = nx.read_edgelist(file_name)\n",
    "\n",
    "nx.set_edge_attributes(full_graph, 1, name='weight')\n",
    "print(full_graph)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvwyMMaHRdfq"
   },
   "source": [
    "Embedding using stanford's node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANAuvlt2Rdfr",
    "outputId": "4e376c59-8012-4fa4-f236-6d4565f14f6f"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "G = node2vec.Graph(full_graph, directed, p, q)\n",
    "G.preprocess_transition_probs()\n",
    "walks = G.simulate_walks(num_walks, walk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5XqXllFRdfr"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "walks = [list(map(str, walk)) for walk in walks]\n",
    "model = Word2Vec(walks, window=10, min_count=0, sg=1, workers=100)\n",
    "#model.save(\"out.model\") ##uncomment to save vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB73xH0SRdfr"
   },
   "source": [
    "Kmeans and sampled kmeans implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqfoVs_jRdfs",
    "outputId": "d98de8be-201b-43fc-e7a2-eb8280b6ca3e"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "print(model)\n",
    "vector = model.wv[1]\n",
    "print(vector)\n",
    "\n",
    "import threading\n",
    "sem = threading.Semaphore()\n",
    "sem_print = threading.Semaphore()\n",
    "\n",
    "NUMBER_OF_ITERATIONS = 10\n",
    "\n",
    "#k_means_cluster\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.vector = x\n",
    "        self.assigned = y\n",
    "\n",
    "#calculate distance between two points\n",
    "def distance(point1, point2):\n",
    "    dist = [(a - b)**2 for a, b in zip(point1.vector, point2.vector)]\n",
    "    return math.sqrt(sum(dist))\n",
    "\n",
    "#calculate squared distance between two points\n",
    "def distance_sq(point1, point2):\n",
    "    dist = [(a - b)**2 for a, b in zip(point1.vector, point2.vector)]\n",
    "    return sum(dist)\n",
    "\n",
    "#calculate S score of point given array of centers and other points\n",
    "def calculate_silhouette(point, centers, points):\n",
    "    a_i = 0.0\n",
    "    b_i = float('inf')\n",
    "    cluster_size = 0\n",
    "    members = 0\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        if points[i].assigned == point.assigned:\n",
    "            a_i += distance(point, points[i])\n",
    "            members += 1\n",
    "\n",
    "    if members < 2:\n",
    "        return 0\n",
    "    else:\n",
    "        a_i/= (members-1)\n",
    "\n",
    "    for k in range(len(centers)):\n",
    "        if not(k == point.assigned):\n",
    "            sum = 0.0\n",
    "            number = 0\n",
    "            for i in range(len(points)):\n",
    "                if points[i].assigned == k:\n",
    "                    sum += distance(point, points[i])\n",
    "                    number +=1\n",
    "            if not(number == 0):\n",
    "                sum /= number\n",
    "                if sum < b_i:\n",
    "                    b_i = sum\n",
    "\n",
    "    if len(centers) == 1:\n",
    "        b_i = 0\n",
    "\n",
    "    return (b_i - a_i)/max(a_i, b_i)\n",
    "\n",
    "# calculate total silhouette score for clustering\n",
    "def calculate_silhouette_score(points, centers):\n",
    "    ss = 0.0\n",
    "    for point in points:\n",
    "        best_assign = -1\n",
    "        min_dist = float('inf')\n",
    "        for k in range(len(centers)):\n",
    "            if distance(point, centers[k]) < min_dist:\n",
    "                point.assigned = k\n",
    "                min_dist = distance(point, centers[k])\n",
    "\n",
    "    for p in points:\n",
    "        ss += calculate_silhouette(p, centers, points)\n",
    "\n",
    "    return ss/len(points)\n",
    "\n",
    "def calculate_silhouette_score_sampled(points, centers, sample_size):\n",
    "    ss = 0.0\n",
    "    pts_sampled = random.sample(points, sample_size)\n",
    "    for point in pts_sampled:\n",
    "        best_assign = -1\n",
    "        min_dist = float('inf')\n",
    "        for k in range(len(centers)):\n",
    "            if distance(point, centers[k]) < min_dist:\n",
    "                point.assigned = k\n",
    "                min_dist = distance(point, centers[k])\n",
    "\n",
    "    for p in pts_sampled:\n",
    "        ss += calculate_silhouette(p, centers, pts_sampled)\n",
    "\n",
    "    return ss/len(pts_sampled)\n",
    "\n",
    "def k_means_plus_plus_init(points, k_chosen):\n",
    "    ##init with kmeans++##\n",
    "    centroids = []\n",
    "    distances = []\n",
    "    probabilities = []\n",
    "    centroids_index = []\n",
    "\n",
    "    random_first_point = random.randrange(len(points))\n",
    "    centroids.append(points[random_first_point])\n",
    "    centroids_index.append(random_first_point)\n",
    "    sum = 0.0\n",
    "    for p in points:\n",
    "        p.assigned = 0\n",
    "        current = distance_sq(centroids[0], p)\n",
    "        distances.append(current)\n",
    "        sum += current\n",
    "        probabilities.append(sum)\n",
    "    #choose a point with weighted probability for kmeans ++\n",
    "    for i in range(1, k_chosen):\n",
    "        print(\"Finding centroid number \" + str(i))\n",
    "        chosen = random.uniform(0.0, sum)\n",
    "        c = 0\n",
    "        for j in range(len(points)):\n",
    "            if chosen > probabilities[j]:\n",
    "              continue\n",
    "            else:\n",
    "              if j == 0:\n",
    "                c = 0\n",
    "                break\n",
    "              else:\n",
    "                c = j - 1\n",
    "                new = False\n",
    "                while not new:\n",
    "                  for K_old in centroids_index:\n",
    "                    if probabilities[c] == probabilities[K_old]:\n",
    "                      c -= 1\n",
    "                      new = False\n",
    "                      break\n",
    "                    else:\n",
    "                      new = True\n",
    "                if c < 0:\n",
    "                  c = j\n",
    "                break\n",
    "        centroids_index.append(c)\n",
    "        centroids.append(points[c])\n",
    "        sum = 0\n",
    "        for j in range(len(points)):\n",
    "            current = distance_sq(centroids[i], points[j])\n",
    "            if(distances[j] > current):\n",
    "                distances[j] = current\n",
    "                points[j].assigned = i\n",
    "            sum += distances[j]\n",
    "            probabilities[j] = sum\n",
    "    return centroids, centroids_index\n",
    "\n",
    "def k_means_plus_plus(points, k_chosen, max_iter = NUMBER_OF_ITERATIONS):\n",
    "    ##init with kmeans++##\n",
    "    centroids, centroids_index = k_means_plus_plus_init(points, k_chosen)\n",
    "\n",
    "    for iter in range(max_iter):\n",
    "        print(\"Starting kmeans iter \" + str(iter) + \"/\" +str(max_iter))\n",
    "        changed = False\n",
    "        for k in range(k_chosen):\n",
    "            med_vec = []\n",
    "            for j in range(len(points[0].vector)):\n",
    "                med = 0\n",
    "                pts = 0\n",
    "                for p in points:\n",
    "                    if(p.assigned == k):\n",
    "                        med += p.vector[j]\n",
    "                        pts += 1\n",
    "                if not(pts == 0):\n",
    "                  med /= pts\n",
    "                else:\n",
    "                  print(\"FOR K = \" + str(k) + \"zero points were found during iter: \" + str(iter))\n",
    "                med_vec.append(med)\n",
    "            centroids[k] = Point(med_vec, k)\n",
    "\n",
    "        for p in points:\n",
    "            best_dist = float('inf')\n",
    "            best_k = 0\n",
    "            for k in range(k_chosen):\n",
    "                #use square to save time\n",
    "                dist = distance_sq(p, centroids[k])\n",
    "                if(dist < best_dist):\n",
    "                    best_dist = dist\n",
    "                    best_k = k\n",
    "            if not(best_k == p.assigned):\n",
    "                changed = True\n",
    "                p.assigned = best_k\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "        else:\n",
    "            changed = False\n",
    "\n",
    "    #find closest point to centroid\n",
    "    for k in range(k_chosen):\n",
    "        dist = float('inf')\n",
    "        i = -1\n",
    "        for p in range(len(points)):\n",
    "          #square to save time\n",
    "            dist_p = distance_sq(points[p], centroids[k])\n",
    "            if dist_p < dist :\n",
    "                dist = dist_p\n",
    "                i = p\n",
    "        centroids[k] = points[i]\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def obj_fun(points, centroids):\n",
    "  sum = 0.0\n",
    "  for p in points:\n",
    "    mindist = float('inf')\n",
    "    for k in range(len(centroids)):\n",
    "      dist = distance_sq(centroids[k], p)\n",
    "      if dist < mindist:\n",
    "        p.assigned = k\n",
    "        mindist = dist\n",
    "    sum += mindist\n",
    "  return sum\n",
    "\n",
    "def bigKmeansThread(points, k_chosen, sample_size, best_centroids, fopt, result, index):\n",
    "  print(\"Starting thread number: \" + str(index))\n",
    "  pts_sampled = random.sample(points, sample_size)\n",
    "  centroids = k_means_plus_plus(pts_sampled, k_chosen)\n",
    "  this_f = obj_fun(pts_sampled, centroids)\n",
    "  sem.acquire()\n",
    "  if this_f < fopt[0]:\n",
    "    best_centroids = centroids\n",
    "    fopt[0] = this_f\n",
    "    result[index] = True\n",
    "  else:\n",
    "    result[index] = False\n",
    "  sem.release()\n",
    "\n",
    "def bigKmeans(points, k_chosen, sample_size, num_threads = 16, stop_after = 10, max_iter = 3):\n",
    "  best_centroids = []\n",
    "  stop = 0\n",
    "  fopt = [float('inf')] ##useful for threading purposes\n",
    "  iter = 0\n",
    "  while stop < stop_after and iter < max_iter:\n",
    "    threads = [None] * num_threads\n",
    "    results = [None] * num_threads\n",
    "\n",
    "    for i in range(len(threads)):\n",
    "      threads[i] = threading.Thread(target=bigKmeansThread, args=(points, k_chosen, sample_size, best_centroids, fopt, results, i))\n",
    "      threads[i].start()\n",
    "\n",
    "    for i in range(len(threads)):\n",
    "      threads[i].join()\n",
    "\n",
    "    for i in range(len(results)):\n",
    "      if results[i]:\n",
    "        stop += 1\n",
    "    iter += 1\n",
    "    print(\"############################################################\")\n",
    "    print(\"Better result number \" + str(stop) + \"/\" + str(stop_after))\n",
    "    print(\"Iteration number \" + str(iter) + \"/\" + str(max_iter))\n",
    "    print(\"Best score: \" + str(fopt[0]))\n",
    "    print(\"############################################################\")\n",
    "  return best_centroids\n",
    "\n",
    "def find_best_centroids(points):\n",
    "    best_centroids = []\n",
    "    best_score = -1.0\n",
    "    for k in range(int(len(points)/15), len(points)):\n",
    "      print(\"trying K = \" + str(k))\n",
    "      current_score = -1\n",
    "      current_centroids = k_means_plus_plus(points, k)\n",
    "      current_score = calculate_silhouette_score(points, current_centroids)\n",
    "      if(current_score >= best_score):\n",
    "          best_centroids = current_centroids\n",
    "          best_score = current_score\n",
    "      else:\n",
    "            return best_centroids\n",
    "\n",
    "def find_best_centroids_big(points, sample_size):\n",
    "    best_centroids = []\n",
    "    best_score = -1.0\n",
    "    for k in range(int(sample_size/15), sample_size):\n",
    "      print(\"trying K = \" + str(k))\n",
    "      current_score = -1\n",
    "      current_centroids = bigKmeans(points, k, sample_size)\n",
    "      current_score = calculate_silhouette_score_sampled(points, current_centroids, sample_size)\n",
    "      if(current_score >= best_score):\n",
    "          best_centroids = current_centroids\n",
    "          best_score = current_score\n",
    "      else:\n",
    "            return best_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "points_ = []\n",
    "#initialize vector of points to be used in Kmeans++\n",
    "for p in range(full_graph.number_of_nodes()):\n",
    "    points_.append(Point(model.wv[p], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage: uncomment the function you want to use.\n",
    "\n",
    "Use Kmeans ++ and silhouette score computation to find a good clustering, VERY SLOW\n",
    "\n",
    "    > best_c = find_best_centroids(points_)\n",
    "\n",
    "Use Kmeans ++ computation to find a good clustering given k, VERY SLOW\n",
    "\n",
    "    > best_c = k_means_plus_plus(points_, k)\n",
    "\n",
    "Use Kmeans ++ and silhouette score computation on random samples to find a good clustering, SLOW\n",
    "\n",
    "    > best_c = find_best_centroids_big(points_, sample_size)\n",
    "\n",
    "Use Kmeans ++ computation to find a good clustering given k on random samples, FASTEST\n",
    "\n",
    "    > best_c = bigKmeans(points_, k, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mRM339ARdft",
    "outputId": "2630ba06-9caf-46fa-b24d-1b5308decf26"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "import math\n",
    "best_c = []\n",
    "sample_size = int(math.sqrt(len(points_)))\n",
    "print(\"calculating best k-means using a sample of \" + str(sample) + \" vectors\")\n",
    "k = int(sample_size/20)\n",
    "##best_c = find_best_centroids(points_)\n",
    "##best_c = k_means_plus_plus(points_, k)\n",
    "#best_c = bigKmeans(points_, k, sample_size)\n",
    "best_c = find_best_centroids_big(points_, sample_size)\n",
    "clustered = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "for p in points_:\n",
    "    min_dist = float('inf')\n",
    "    for k in range(len(best_c)):\n",
    "        dist_ = distance(p, best_c[k])\n",
    "        if(dist_ < min_dist):\n",
    "            min_dist = dist_\n",
    "            p.assigned = k\n",
    "\n",
    "target_cluster = points_[target].assigned\n",
    "\n",
    "for p in range(len(points_)):\n",
    "    if points_[p].assigned == target_cluster:\n",
    "        clustered.append(p)\n",
    "\n",
    "print(clustered)\n",
    "clustered_graph = full_graph.subgraph(clustered)\n",
    "print(\"Clustered graph: \" + str(clustered_graph))\n",
    "#Remove nodes that are not connected\n",
    "if(directed):\n",
    "  u = clustered_graph.to_undirected()\n",
    "  nodes = nx.node_connected_component(u, target)\n",
    "  clustered_graph = clustered_graph.subgraph(nodes)\n",
    "else:\n",
    "  clustered_graph = nx.node_connected_component(clustered_graph, target)\n",
    "print(\"Clustered graph's connected component with target node: \" + str(clustered_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6BsJ8GlRdft",
    "outputId": "9c9e23d3-baa7-47f8-b286-dcbbecc080e9"
   },
   "outputs": [],
   "source": [
    "#Clustering global cc\n",
    "average_cluster_coef = nx.average_clustering(clustered_graph)\n",
    "\n",
    "print(f\"Coefficiente di clustering medio: {average_cluster_coef}\")\n",
    "\n",
    "\n",
    "\n",
    "#Clustering per ogni nodo (restituisce un dizionario)\n",
    "node_cluster_coefs = nx.clustering(clustered_graph)\n",
    "\n",
    "for node, cluster_coef in node_cluster_coefs.items():\n",
    "    print(f\"Nodo {node}: Coefficiente di clustering = {cluster_coef}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPHd-FAcRdfu"
   },
   "source": [
    "Valutazione nodi (usare clustered_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8isCZgkRdfu"
   },
   "outputs": [],
   "source": [
    "#Valutazione nodi con CC o altre metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t4rr9wPJRdfv"
   },
   "outputs": [],
   "source": [
    "#Ricerca cliques\n",
    "\n",
    "#lettura file di esempio, costruzione nodes e edges\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "current_directory = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "filename = \"grafo_esempio.txt\"\n",
    "\n",
    "graph = nx.Graph()\n",
    "graph = nx.read_edgelist(filename, nodetype=int, create_using=nx.DiGraph)\n",
    "nx.set_edge_attributes(graph, 1, name='weight')\n",
    "print(graph)\n",
    "\n",
    "print(\"Edges:\", graph.edges)\n",
    "print(\"Unique Node IDs:\", graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ZXji37fVRdfv"
   },
   "outputs": [],
   "source": [
    "#funzione per il neighbor\n",
    "def n(v, edges):\n",
    "    neighbors = set()\n",
    "    for edge in edges:\n",
    "        if v in edge:\n",
    "            neighbors.update(edge)\n",
    "\n",
    "    neighbors.discard(v)\n",
    "\n",
    "    return list(neighbors)\n",
    "\n",
    "#Bron-Kerbosch algorithm with pivot\n",
    "def BronKerbosch(R, P, X, edges, cliques):\n",
    "    if not P and not X:\n",
    "        # P and X are both empty, report R as a maximal clique\n",
    "        cliques.append(R)\n",
    "        return\n",
    "\n",
    "    # Choose a pivot vertex u in P ⋃ X\n",
    "    pivot = (set(P) | set(X)).pop()\n",
    "\n",
    "    for v in set(P) - set(n(pivot, edges)):\n",
    "        # Recursively explore the neighborhood of v\n",
    "        BronKerbosch(R + [v], list(set(P) & set(n(v, edges))), list(set(X) & set(n(v, edges))), edges, cliques)\n",
    "\n",
    "        # Remove v from P and add it to X\n",
    "        P.remove(v)\n",
    "        X.append(v)\n",
    "\n",
    "#funzione per la clique massima\n",
    "def maxClique(cliques):\n",
    "    return max(cliques, key=len, default=[])\n",
    "\n",
    "#funzione per clique del target\n",
    "def nodeCliques(all_cliques, selected_node):\n",
    "    node_cliques = []\n",
    "    for clique in all_cliques:\n",
    "        if selected_node in clique:\n",
    "            node_cliques.append(clique)\n",
    "    return node_cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KW3YjSXMRdfw"
   },
   "outputs": [],
   "source": [
    "#Clustering global cc\n",
    "def runNodeCC(graph):\n",
    "    #average_cluster_coef = nx.average_clustering(graph)\n",
    "    #print(f\"Coefficiente di clustering medio: {average_cluster_coef}\")\n",
    "\n",
    "    #Clustering per ogni nodo (restituisce un dizionario)\n",
    "    node_cluster_coefs = nx.clustering(graph)\n",
    "\n",
    "    #for node, cluster_coef in node_cluster_coefs.items():\n",
    "        #print(f\"Nodo {node}: Coefficiente di clustering = {cluster_coef}\")\n",
    "        \n",
    "    return node_cluster_coefs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "DYpmaXHJRdfw"
   },
   "outputs": [],
   "source": [
    "#node clique with max cc\n",
    "def bestClique(node_cliques, node_cluster_coefs):\n",
    "    max_cc = 0\n",
    "    best_clique = []\n",
    "    for clique in node_cliques:\n",
    "        avg_cc = 0;\n",
    "        for node in clique:\n",
    "            avg_cc += node_cluster_coefs[node]\n",
    "\n",
    "        if avg_cc/len(clique) > max_cc:\n",
    "            best_clique = clique\n",
    "    return best_clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYpmaXHJRdfw"
   },
   "outputs": [],
   "source": [
    "#Ricerca e stampa le cliques e la clique massima\n",
    "all_cliques = []\n",
    "selected_node = 3\n",
    "BronKerbosch([], list(graph.nodes), [], graph.edges, all_cliques)\n",
    "node_cliques = nodeCliques(all_cliques, selected_node)\n",
    "print(\"Cliques nodo:\")\n",
    "print(node_cliques)\n",
    "print(\"Best clique\")\n",
    "print(bestClique(node_cliques, runNodeCC(graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMlb6EQpRdfw"
   },
   "outputs": [],
   "source": [
    "#Tentativi con rimozioni casuali\n",
    "import random\n",
    "\n",
    "# Numero di nodi da rimuovere ad ogni iterazione\n",
    "n_nodes_to_remove = 10\n",
    "\n",
    "# Numero totale di iterazioni\n",
    "n_iterations = 100\n",
    "\n",
    "# Copia del grafo iniziale\n",
    "graph_to_modify = graph.copy()\n",
    "\n",
    "#results\n",
    "results = []\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Escludere il target\n",
    "    filtered_nodes = [element for element in list(graph_to_modify.nodes()) if element != selected_node]\n",
    "    \n",
    "    # Rimuovi n nodi casuali dal grafo\n",
    "    nodes_to_remove = random.sample(filtered_nodes, n_nodes_to_remove)\n",
    "    updated_graph = graph_to_modify.copy()\n",
    "    updated_graph.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Stampa o elabora i risultati desiderati\n",
    "    print(f\"Iteration {iteration + 1}: Removed nodes {nodes_to_remove}\")\n",
    "\n",
    "    all_cliques = []\n",
    "    BronKerbosch([], list(updated_graph.nodes), [], updated_graph.edges, all_cliques)\n",
    "    node_cliques = nodeCliques(all_cliques, selected_node)\n",
    "    print(\"Cliques nodo:\")\n",
    "    print(node_cliques)\n",
    "    best_clique = bestClique(node_cliques, runNodeCC(updated_graph))\n",
    "    print(\"Best clique\")\n",
    "    print(best_clique)\n",
    "    results.append(best_clique)\n",
    "    \n",
    "    # Aggiorna il grafo originale per la prossima iterazione\n",
    "    #graph_to_modify = updated_graph.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot results\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_histogram(array_of_arrays):\n",
    "    # Convert inner arrays to tuples and use Counter\n",
    "    element_counts = Counter(tuple(inner_array) for inner_array in array_of_arrays)\n",
    "\n",
    "    # Extract elements and their counts\n",
    "    elements = list(element_counts.keys())\n",
    "    counts = list(element_counts.values())\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.bar(range(len(elements)), counts, align='center')\n",
    "    plt.xticks(range(len(elements)), elements)\n",
    "    plt.xlabel('Best clique')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of results obtained')\n",
    "    \n",
    "    # Annotate each bar with its count\n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "generate_histogram(results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
