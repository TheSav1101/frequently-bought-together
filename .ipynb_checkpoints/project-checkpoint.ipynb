{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqVzrDURRdfh"
   },
   "source": [
    "Frequently Bought Toghether Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWZstf_yRdfm"
   },
   "source": [
    "Inizializzazione, parametri e altre cose che tutti devono sapere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JerKv_BSSvXx",
    "outputId": "12beacc8-07b2-4a44-ea12-9425e9e2c13c"
   },
   "outputs": [],
   "source": [
    "#####ONLY USE WITH COLAB##########\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "import os\n",
    "os.chdir(\"drive/MyDrive/_COLAB\")\n",
    "#####ONLY USE WITH COLAB##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxvzxjEORdfn"
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "import random\n",
    "import networkx as nx\n",
    "import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#Nodo target\n",
    "target = 3\n",
    "\n",
    "#Grafo completo FBT\n",
    "full_graph = nx.Graph()\n",
    "\n",
    "#Grafo cluster selezionato\n",
    "clustered_graph = nx.Graph()\n",
    "\n",
    "#File di lettura\n",
    "file_name = \"Amazon0302.txt\"\n",
    "#file_name = \"grafo_esempio.txt\"\n",
    "\n",
    "#Grafo directed se True o uniderected se False\n",
    "directed = True\n",
    "\n",
    "#embedding hyperparameters\n",
    "#default = 1, 1, 10, 80\n",
    "p=1\n",
    "q=1\n",
    "num_walks=10\n",
    "walk_length=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiyIb2ksRdfq",
    "outputId": "7fa80a6c-7b8f-4c7e-f7e5-dde834095443"
   },
   "outputs": [],
   "source": [
    "### LOAD GRAPH ###\n",
    "print(\"loading graph \" + file_name)\n",
    "\n",
    "if directed:\n",
    "    ##genera il grafo directed utilizzando nx.DiGraph\n",
    "    full_graph = nx.read_edgelist(file_name, nodetype=int, create_using=nx.DiGraph)\n",
    "\n",
    "else:\n",
    "    ##genera il grafo undirected utilizzando nx.Graph\n",
    "    full_graph = nx.read_edgelist(file_name)\n",
    "\n",
    "nx.set_edge_attributes(full_graph, 1, name='weight')\n",
    "print(full_graph)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvwyMMaHRdfq"
   },
   "source": [
    "Embedding using stanford's node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANAuvlt2Rdfr",
    "outputId": "96938dcc-2d31-4581-afcf-df191744383a"
   },
   "outputs": [],
   "source": [
    "G = node2vec.Graph(full_graph, directed, p, q)\n",
    "G.preprocess_transition_probs()\n",
    "walks = G.simulate_walks(num_walks, walk_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5XqXllFRdfr"
   },
   "outputs": [],
   "source": [
    "walks = [list(map(str, walk)) for walk in walks]\n",
    "model = Word2Vec(walks, window=10, min_count=0, sg=1, workers=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a3zOp1lLXMs"
   },
   "outputs": [],
   "source": [
    "model.save(\"out.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB73xH0SRdfr"
   },
   "source": [
    "Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqfoVs_jRdfs",
    "outputId": "bb28d063-b19e-4426-f805-c6fa17de3040"
   },
   "outputs": [],
   "source": [
    "print(model)\n",
    "vector = model.wv[1]\n",
    "print(vector)\n",
    "\n",
    "import threading\n",
    "sem = threading.Semaphore()\n",
    "sem_print = threading.Semaphore()\n",
    "\n",
    "NUMBER_OF_ITERATIONS = 10\n",
    "\n",
    "#k_means_cluster\n",
    "class Point:\n",
    "    def __init__(self, x, y):\n",
    "        self.vector = x\n",
    "        self.assigned = y\n",
    "\n",
    "#calculate distance between two points\n",
    "def distance(point1, point2):\n",
    "    dist = [(a - b)**2 for a, b in zip(point1.vector, point2.vector)]\n",
    "    return math.sqrt(sum(dist))\n",
    "\n",
    "#calculate S score of point given array of centers and other points\n",
    "def calculate_silhouette(point, centers, points):\n",
    "    a_i = 0.0\n",
    "    b_i = float('inf')\n",
    "    cluster_size = 0\n",
    "    members = 0\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        if points[i].assigned == point.assigned:\n",
    "            a_i += distance(point, points[i])\n",
    "            members += 1\n",
    "\n",
    "    if members < 2:\n",
    "        return 0\n",
    "    else:\n",
    "        a_i/= (members-1)\n",
    "\n",
    "    for k in range(len(centers)):\n",
    "        if not(k == point.assigned):\n",
    "            sum = 0.0\n",
    "            number = 0\n",
    "            for i in range(len(points)):\n",
    "                if points[i].assigned == k:\n",
    "                    sum += distance(point, points[i])\n",
    "                    number +=1\n",
    "            if not(number == 0):\n",
    "                sum /= number\n",
    "                if sum < b_i:\n",
    "                    b_i = sum\n",
    "\n",
    "    if len(centers) == 1:\n",
    "        b_i = 0\n",
    "\n",
    "    return (b_i - a_i)/max(a_i, b_i)\n",
    "\n",
    "# calculate total silhouette score for clustering\n",
    "def calculate_silhouette_score(points, centers):\n",
    "    ss = 0.0\n",
    "    for point in points:\n",
    "        best_assign = -1\n",
    "        min_dist = float('inf')\n",
    "        for k in range(len(centers)):\n",
    "            if distance(point, centers[k]) < min_dist:\n",
    "                point.assigned = k\n",
    "                min_dist = distance(point, centers[k])\n",
    "\n",
    "    for p in points:\n",
    "        ss += calculate_silhouette(p, centers, points)\n",
    "\n",
    "    return ss/len(points)\n",
    "\n",
    "def calculate_silhouette_score_sampled(points, centers, sample_size):\n",
    "    ss = 0.0\n",
    "    pts_sampled = random.sample(points, sample_size)\n",
    "    for point in pts_sampled:\n",
    "        best_assign = -1\n",
    "        min_dist = float('inf')\n",
    "        for k in range(len(centers)):\n",
    "            if distance(point, centers[k]) < min_dist:\n",
    "                point.assigned = k\n",
    "                min_dist = distance(point, centers[k])\n",
    "\n",
    "    for p in pts_sampled:\n",
    "        ss += calculate_silhouette(p, centers, pts_sampled)\n",
    "\n",
    "    return ss/len(pts_sampled)\n",
    "\n",
    "def k_means_plus_plus_init(points, k_chosen):\n",
    "    ##init with kmeans++##\n",
    "    centroids = []\n",
    "    distances = []\n",
    "    probabilities = []\n",
    "    centroids_index = []\n",
    "\n",
    "    random_first_point = random.randrange(len(points))\n",
    "    centroids.append(points[random_first_point])\n",
    "    centroids_index.append(random_first_point)\n",
    "    sum = 0.0\n",
    "    for p in points:\n",
    "        p.assigned = 0\n",
    "        current = distance(centroids[0], p)\n",
    "        distances.append(current)\n",
    "        sum += current**2\n",
    "        probabilities.append(sum)\n",
    "    #choose a point with weighted probability for kmeans ++\n",
    "    for i in range(1, k_chosen):\n",
    "        print(\"Finding centroid number \" + str(i))\n",
    "        chosen = random.uniform(0.0, sum)\n",
    "        c = 0\n",
    "        for j in range(len(points)):\n",
    "            if chosen > probabilities[j]:\n",
    "              continue\n",
    "            else:\n",
    "              if j == 0:\n",
    "                c = 0\n",
    "                break\n",
    "              else:\n",
    "                c = j - 1\n",
    "                new = False\n",
    "                while not new:\n",
    "                  for K_old in centroids_index:\n",
    "                    if probabilities[c] == probabilities[K_old]:\n",
    "                      c -= 1\n",
    "                      new = False\n",
    "                      break\n",
    "                    else:\n",
    "                      new = True\n",
    "                if c < 0:\n",
    "                  c = j\n",
    "                break\n",
    "        centroids_index.append(c)\n",
    "        centroids.append(points[c])\n",
    "        sum = 0\n",
    "        for j in range(len(points)):\n",
    "            current = distance(centroids[i], points[j])\n",
    "            if(distances[j] > current):\n",
    "                distances[j] = current\n",
    "                points[j].assigned = i\n",
    "            sum += distances[j]**2\n",
    "            probabilities[j] = sum\n",
    "    return centroids, centroids_index\n",
    "\n",
    "def k_means_plus_plus(points, k_chosen):\n",
    "    ##init with kmeans++##\n",
    "    centroids, centroids_index = k_means_plus_plus_init(points, k_chosen)\n",
    "\n",
    "    for iter in range(NUMBER_OF_ITERATIONS):\n",
    "        changed = False\n",
    "        for k in range(k_chosen):\n",
    "            med_vec = []\n",
    "            for j in range(len(points[0].vector)):\n",
    "                med = 0\n",
    "                pts = 0\n",
    "                for p in points:\n",
    "                    if(p.assigned == k):\n",
    "                        med += p.vector[j]\n",
    "                        pts += 1\n",
    "                if not(pts == 0):\n",
    "                  med /= pts\n",
    "                else:\n",
    "                  print(\"FOR K = \" + str(k) + \"zero points were found during iter: \" + str(iter))\n",
    "                med_vec.append(med)\n",
    "            centroids[k] = Point(med_vec, k)\n",
    "\n",
    "        for p in points:\n",
    "            best_dist = float('inf')\n",
    "            best_k = 0\n",
    "            for k in range(k_chosen):\n",
    "                dist = distance(p, centroids[k])\n",
    "                if(dist < best_dist):\n",
    "                    best_dist = dist\n",
    "                    best_k = k\n",
    "            if not(best_k == p.assigned):\n",
    "                changed = True\n",
    "                p.assigned = best_k\n",
    "\n",
    "        if not changed:\n",
    "            break\n",
    "        else:\n",
    "            changed = False\n",
    "\n",
    "    #find closest point to centroid\n",
    "    for k in range(k_chosen):\n",
    "        dist = float('inf')\n",
    "        i = -1\n",
    "        for p in range(len(points)):\n",
    "            dist_p = distance(points[p], centroids[k])\n",
    "            if dist_p < dist :\n",
    "                dist = dist_p\n",
    "                i = p\n",
    "        centroids[k] = points[i]\n",
    "\n",
    "    return centroids\n",
    "\n",
    "def obj_fun(points, centroids):\n",
    "  sum = 0.0\n",
    "  for p in points:\n",
    "    mindist = float('inf')\n",
    "    for k in range(len(centroids)):\n",
    "      dist = distance(centroids[k], p)\n",
    "      if dist < mindist:\n",
    "        p.assigned = k\n",
    "        mindist = dist\n",
    "    sum += mindist**2\n",
    "  return sum\n",
    "\n",
    "def bigKmeansThread(points, k_chosen, sample_size, best_centroids, fopt, result, index):\n",
    "  print(\"Starting thread number: \" + str(index))\n",
    "  pts_sampled = random.sample(points, sample_size)\n",
    "  centroids = k_means_plus_plus(pts_sampled, k_chosen)\n",
    "  this_f = obj_fun(pts_sampled, centroids)\n",
    "  sem.acquire()\n",
    "  if this_f < fopt[0]:\n",
    "    best_centroids = centroids\n",
    "    fopt[0] = this_f\n",
    "    result[index] = True\n",
    "  else:\n",
    "    result[index] = False\n",
    "  sem.release()\n",
    "\n",
    "def bigKmeans(points, k_chosen, sample_size, num_threads = 8, stop_after = 15, max_iter = 5):\n",
    "  best_centroids = []\n",
    "  stop = 0\n",
    "  fopt = [float('inf')] ##useful for threading purposes\n",
    "  iter = 0\n",
    "  while stop < stop_after and iter < max_iter:\n",
    "    threads = [None] * num_threads\n",
    "    results = [None] * num_threads\n",
    "\n",
    "    for i in range(len(threads)):\n",
    "      threads[i] = threading.Thread(target=bigKmeansThread, args=(points, k_chosen, sample_size, best_centroids, fopt, results, i))\n",
    "      threads[i].start()\n",
    "\n",
    "    for i in range(len(threads)):\n",
    "      threads[i].join()\n",
    "\n",
    "    for i in range(len(results)):\n",
    "      if results[i]:\n",
    "        stop += 1\n",
    "    iter += 1\n",
    "    print(\"############################################################\")\n",
    "    print(\"Better result number \" + str(stop) + \"/\" + str(stop_after))\n",
    "    print(\"Iteration number \" + str(iter) + \"/\" + str(max_iter))\n",
    "    print(\"Best score: \" + str(fopt[0]))\n",
    "    print(\"############################################################\")\n",
    "  return best_centroids\n",
    "\n",
    "def find_best_centroids(points):\n",
    "    best_centroids = []\n",
    "    best_score = -1.0\n",
    "    for k in range(len(points)/150, len(points)):\n",
    "      print(\"trying K = \" + str(k))\n",
    "      current_score = -1\n",
    "      current_centroids = k_means_plus_plus(points, k)\n",
    "      current_score = calculate_silhouette_score(points, current_centroids)\n",
    "      if(current_score >= best_score):\n",
    "          best_centroids = current_centroids\n",
    "          best_score = current_score\n",
    "      else:\n",
    "            return best_centroids\n",
    "\n",
    "def find_best_centroids_big(points, sample_size):\n",
    "    best_centroids = []\n",
    "    best_score = -1.0\n",
    "    for k in range(len(points)/150, len(points)):\n",
    "      print(\"trying K = \" + str(k))\n",
    "      current_score = -1\n",
    "      current_centroids = bigKmeans(points, k, sample_size)\n",
    "      current_score = calculate_silhouette_score_sampled(points, current_centroids, sample_size)\n",
    "      if(current_score >= best_score):\n",
    "          best_centroids = current_centroids\n",
    "          best_score = current_score\n",
    "      else:\n",
    "            return best_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJAFcS7nK8zU"
   },
   "outputs": [],
   "source": [
    "points_ = []\n",
    "#initialize vector of points to be used in Kmeans++\n",
    "for p in range(full_graph.number_of_nodes()):\n",
    "    points_.append(Point(model.wv[p], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKQD_QtQ2pzM",
    "outputId": "aed1fc94-b5e5-45b2-9437-475f2e6574cd"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "best_c = []\n",
    "##best_c = find_best_centroids(points_)\n",
    "##best_c = k_means_plus_plus(points_, 74000)\n",
    "sample = int(math.sqrt(len(points_))*20)\n",
    "print(\"calculating best k-means using a sample of \" + str(sample) + \" vectors\")\n",
    "#best_c = bigKmeans(points_, 5, sample)\n",
    "best_c = find_best_centroids_big(points_, sample)\n",
    "clustered = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mRM339ARdft",
    "outputId": "2f0f308c-0965-4728-f91e-dd867a5695af"
   },
   "outputs": [],
   "source": [
    "for p in points_:\n",
    "    min_dist = float('inf')\n",
    "    for k in range(len(best_c)):\n",
    "        dist_ = distance(p, best_c[k])\n",
    "        if(dist_ < min_dist):\n",
    "            min_dist = dist_\n",
    "            p.assigned = k\n",
    "\n",
    "target_cluster = points_[target].assigned\n",
    "\n",
    "for p in range(len(points_)):\n",
    "    if points_[p].assigned == target_cluster:\n",
    "        clustered.append(p)\n",
    "\n",
    "print(clustered)\n",
    "clustered_graph = full_graph.subgraph(clustered)\n",
    "print(\"Clustered graph: \" + str(clustered_graph))\n",
    "#Remove nodes that are not connected\n",
    "if(directed):\n",
    "  u = clustered_graph.to_undirected()\n",
    "  nodes = nx.node_connected_component(u, target)\n",
    "  clustered_graph = clustered_graph.subgraph(nodes)\n",
    "else:\n",
    "  clustered_graph = nx.node_connected_component(clustered_graph, target)\n",
    "print(\"Clustered graph's connected component with target node: \" + str(clustered_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T6BsJ8GlRdft",
    "outputId": "482ef6bf-1a55-45b0-ec05-91a3640159da"
   },
   "outputs": [],
   "source": [
    "#Clustering global cc\n",
    "average_cluster_coef = nx.average_clustering(clustered_graph)\n",
    "\n",
    "print(f\"Coefficiente di clustering medio: {average_cluster_coef}\")\n",
    "\n",
    "#Clustering per ogni nodo (restituisce un dizionario)\n",
    "node_cluster_coefs = nx.clustering(clustered_graph)\n",
    "\n",
    "for node, cluster_coef in node_cluster_coefs.items():\n",
    "    print(f\"Nodo {node}: Coefficiente di clustering = {cluster_coef}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPHd-FAcRdfu"
   },
   "source": [
    "Valutazione nodi (usare clustered_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8isCZgkRdfu"
   },
   "outputs": [],
   "source": [
    "#Valutazione nodi con CC o altre metriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4rr9wPJRdfv",
    "outputId": "2ebbf715-a447-45ab-9948-58e934f8e830"
   },
   "outputs": [],
   "source": [
    "#Ricerca cliques\n",
    "\n",
    "#lettura file di esempio, costruzione nodes e edges\n",
    "import os\n",
    "import networkx as nx\n",
    "\n",
    "current_directory = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "filename = \"grafo_esempio.txt\"\n",
    "\n",
    "graph = nx.Graph()\n",
    "graph = nx.read_edgelist(filename, nodetype=int, create_using=nx.DiGraph)\n",
    "nx.set_edge_attributes(graph, 1, name='weight')\n",
    "print(graph)\n",
    "\n",
    "print(\"Edges:\", graph.edges)\n",
    "print(\"Unique Node IDs:\", graph.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZXji37fVRdfv",
    "outputId": "87b8e371-09a0-4423-8c86-5a6f9ef6de19"
   },
   "outputs": [],
   "source": [
    "#funzione per il neighbor\n",
    "def n(v, edges):\n",
    "    neighbors = set()\n",
    "    for edge in edges:\n",
    "        if v in edge:\n",
    "            neighbors.update(edge)\n",
    "\n",
    "    neighbors.discard(v)\n",
    "\n",
    "    return list(neighbors)\n",
    "\n",
    "#Bron-Kerbosch algorithm with pivot\n",
    "def BronKerbosch(R, P, X, edges, cliques):\n",
    "    if not P and not X:\n",
    "        # P and X are both empty, report R as a maximal clique\n",
    "        cliques.append(R)\n",
    "        return\n",
    "\n",
    "    # Choose a pivot vertex u in P ⋃ X\n",
    "    pivot = (set(P) | set(X)).pop()\n",
    "\n",
    "    for v in set(P) - set(n(pivot, edges)):\n",
    "        # Recursively explore the neighborhood of v\n",
    "        BronKerbosch(R + [v], list(set(P) & set(n(v, edges))), list(set(X) & set(n(v, edges))), edges, cliques)\n",
    "\n",
    "        # Remove v from P and add it to X\n",
    "        P.remove(v)\n",
    "        X.append(v)\n",
    "\n",
    "#funzione per la clique massima\n",
    "def maxClique(cliques):\n",
    "    return max(cliques, key=len, default=[])\n",
    "\n",
    "#Ricerca e stampa le cliques e la clique massima\n",
    "all_cliques = []\n",
    "node_cliques = []\n",
    "selected_node = 10\n",
    "BronKerbosch([], list(graph.nodes), [], graph.edges, all_cliques)\n",
    "print(\"Cliques:\")\n",
    "for clique in all_cliques:\n",
    "    if selected_node in clique:\n",
    "        node_cliques.append(clique)\n",
    "\n",
    "print(node_cliques)\n",
    "\n",
    "print(\"Maximum Clique:\", maxClique(node_cliques))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KW3YjSXMRdfw",
    "outputId": "5f575a1e-d406-4a0f-cfa6-84d83a36c278"
   },
   "outputs": [],
   "source": [
    "#Clustering global cc\n",
    "average_cluster_coef = nx.average_clustering(graph)\n",
    "\n",
    "print(f\"Coefficiente di clustering medio: {average_cluster_coef}\")\n",
    "\n",
    "\n",
    "\n",
    "#Clustering per ogni nodo (restituisce un dizionario)\n",
    "node_cluster_coefs = nx.clustering(graph)\n",
    "\n",
    "for node, cluster_coef in node_cluster_coefs.items():\n",
    "    print(f\"Nodo {node}: Coefficiente di clustering = {cluster_coef}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYpmaXHJRdfw",
    "outputId": "3a2ca49a-bf07-4a94-98f5-82a8de3749cd"
   },
   "outputs": [],
   "source": [
    "#node clique with max cc\n",
    "max_cc = 0\n",
    "best_clique = []\n",
    "for clique in node_cliques:\n",
    "    avg_cc = 0;\n",
    "    for node in clique:\n",
    "        avg_cc += node_cluster_coefs[node]\n",
    "\n",
    "    if avg_cc/len(clique) > max_cc:\n",
    "        best_clique = clique\n",
    "\n",
    "print(best_clique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "eMlb6EQpRdfw",
    "outputId": "cbec3419-1cb8-4b2d-d22c-8c628d338fd9"
   },
   "outputs": [],
   "source": [
    "#Tentativi con rimozioni casuali\n",
    "import random\n",
    "\n",
    "# Numero di nodi da rimuovere ad ogni iterazione\n",
    "n_nodes_to_remove = 1\n",
    "\n",
    "# Numero totale di iterazioni\n",
    "n_iterations = 10\n",
    "\n",
    "# Copia del grafo iniziale\n",
    "graph_to_modify = full_graph.copy()\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Rimuovi n nodi casuali dal grafo\n",
    "    nodes_to_remove = random.sample(list(graph_to_modify.nodes()), n_nodes_to_remove)\n",
    "    updated_graph = graph_to_modify.copy()\n",
    "    updated_graph.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Stampa o elabora i risultati desiderati\n",
    "    print(f\"Iteration {iteration + 1}: Removed nodes {nodes_to_remove}\")\n",
    "\n",
    "    # Aggiorna il grafo originale per la prossima iterazione\n",
    "    original_graph = updated_graph.copy()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
