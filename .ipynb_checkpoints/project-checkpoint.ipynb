{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqVzrDURRdfh"
   },
   "source": [
    "Frequently Bought Toghether Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWZstf_yRdfm"
   },
   "source": [
    "Inizializzazione, parametri e altre cose che tutti devono sapere\n",
    "\n",
    "> Indented block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JerKv_BSSvXx",
    "outputId": "ceeefce3-b93b-4f39-a76a-0aca2680fa2a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "import os\n",
    "os.chdir(\"drive/MyDrive/_COLAB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxvzxjEORdfn",
    "outputId": "7143288c-20d5-4335-a61b-915e121d628c"
   },
   "outputs": [],
   "source": [
    "#Author: Everyone\n",
    "import random\n",
    "import networkx as nx\n",
    "import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "import os.path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n",
    "import math\n",
    "\n",
    "#Nodo target\n",
    "target = -1 ##modificato in seguito a random\n",
    "\n",
    "#All graphs to be tested\n",
    "graphs = []\n",
    "\n",
    "#directory with data files\n",
    "data_dir = \"data/\"\n",
    "#directory with saved embeddings\n",
    "models_dir = \"models/\"\n",
    "#directory with saved plots\n",
    "plots_dir = \"plots/\"\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "\n",
    "if not os.path.exists(plots_dir):\n",
    "    os.makedirs(plots_dir)\n",
    "\n",
    "#filenames of graph data, should be inside ${data_dir}\n",
    "files = [\"Amazon0302\" , \"Amazon0312\", \"Amazon0505\", \"Amazon0601\", \"AmazonU\"]\n",
    "file_ext = \".txt\"\n",
    "\n",
    "#is represented graph directed?\n",
    "directed = [True, True, True, True, False]\n",
    "\n",
    "#embedding hyperparameters\n",
    "#default = 1, 1, 10, 80\n",
    "p=1\n",
    "q=1\n",
    "num_walks=10\n",
    "walk_length=80\n",
    "\n",
    "### LOAD GRAPHS ###\n",
    "for i in range(len(files)):\n",
    "    print(\"loading graph \" + data_dir + files[i] + file_ext)\n",
    "    if directed[i]:\n",
    "        ##genera il grafo directed utilizzando nx.DiGraph\n",
    "        graphs.append(nx.read_edgelist(data_dir + files[i] + file_ext, nodetype=int, create_using=nx.DiGraph))\n",
    "\n",
    "    else:\n",
    "        ##genera il grafo undirected utilizzando nx.Graph\n",
    "        graphs.append(nx.read_edgelist(data_dir + files[i] + file_ext))\n",
    "\n",
    "    nx.set_edge_attributes(graphs[i], 1, name='weight')\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvwyMMaHRdfq"
   },
   "source": [
    "Embedding using stanford's node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ANAuvlt2Rdfr"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "#store all node2vec models\n",
    "models = []\n",
    "\n",
    "for i in range(len(graphs)):\n",
    "    filename = models_dir + files[i] + \".model\"\n",
    "    saved = False\n",
    "    if(os.path.isfile(filename)):\n",
    "      saved = True\n",
    "    if(saved):\n",
    "      models.append(Word2Vec.load(filename))\n",
    "      print(\"Saved model found for file \" + filename)\n",
    "    else:\n",
    "      print(\"No saved model found for file \" + filename + \", generating embedding...\")\n",
    "      G = node2vec.Graph(graphs[i], directed[i], p, q)\n",
    "      G.preprocess_transition_probs()\n",
    "      walks = G.simulate_walks(num_walks, walk_length)\n",
    "      walks = [list(map(str, walk)) for walk in walks]\n",
    "      models.append(Word2Vec(walks, window=10, min_count=0, sg=1, workers=100))\n",
    "      models[i].save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB73xH0SRdfr"
   },
   "source": [
    "Clustering with kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjhzq4s3GbCm"
   },
   "outputs": [],
   "source": [
    "#Author: Savoia Emanuele\n",
    "\n",
    "##Min tolerated sh score to proceed is: [best_score - max_error]\n",
    "max_error = 0.025\n",
    "\n",
    "#use sklearn implementation of kmeans++ combined with silhouette score to find best k and clustering\n",
    "# if sampled is True use MiniBatchKMeans instead of kmeans\n",
    "def sklearn_kmeans_find_k(points, sampled=True):\n",
    "  start_time = time.time()\n",
    "  #best clustering until this iteration\n",
    "  best_clustering = []\n",
    "  #array of scores used for plot\n",
    "  scores = []\n",
    "  #array of K associated with scores, used for plot\n",
    "  k_tried = []\n",
    "  #best silhouette until now\n",
    "  best_score = -1.0\n",
    "  #mnimum k value\n",
    "  min_k = int(math.sqrt(len(points))*4.5)\n",
    "  for k in range(min_k, len(points), 15):\n",
    "    print(\"trying kmeans with k = \" + str(k))\n",
    "    score = -1.0\n",
    "    clustering = []\n",
    "    if sampled:\n",
    "      #choose sample size based on k and vector size\n",
    "      sample_size = int(len(points)/100)\n",
    "      if sample_size < int(k*7.75):\n",
    "        sample_size = int(k*7.75)\n",
    "        if(sample_size < 1024 and len(points) >= 1024):\n",
    "          sample_size = 1024\n",
    "        elif(sample_size > len(points)):\n",
    "          sample_size = len(points)\n",
    "      #run kmeans++ with mini batches\n",
    "      kmeans = MiniBatchKMeans(n_clusters=k, init='k-means++', batch_size=sample_size, n_init='auto')\n",
    "      clustering = kmeans.fit_predict(points)\n",
    "    else:\n",
    "      #run kmeans++\n",
    "      kmeans = KMeans(n_clusters=k, init='k-means++', n_init='auto')\n",
    "      clustering = kmeans.fit_predict(points)\n",
    "    #calculate silhouette from sample\n",
    "    score = silhouette_score(points, clustering, sample_size=min_k*10)\n",
    "    print(\"> Current silhouette score:   \" + str(score))\n",
    "    print(\"> Last best silhouette score: \" + str(best_score))\n",
    "    #update results and check if within parameters\n",
    "    if score >= best_score:\n",
    "      best_clustering = clustering\n",
    "      best_score = score\n",
    "      scores.append(score)\n",
    "      k_tried.append(k)\n",
    "    elif score >= best_score - max_error:\n",
    "      scores.append(score)\n",
    "      k_tried.append(k)\n",
    "    else:\n",
    "      print(\"Time since start: \" + str(time.time() - start_time))\n",
    "      return best_clustering, scores, k_tried\n",
    "\n",
    "def plot_save_scores(scores, k_tried, title_):\n",
    "  # Data for plotting\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(k_tried, scores)\n",
    "\n",
    "  ax.set(xlabel='k', ylabel='silhouette score',\n",
    "        title=title_)\n",
    "  ax.grid()\n",
    "\n",
    "  fig.savefig(plots_dir + title_ + \".png\")\n",
    "  plt.show()\n",
    "\n",
    "#returns the subgraph with target node inside acording to clustering\n",
    "def reduce_graph_to_cluster_subgraph(graph, directed, c, target):\n",
    "  clustered = []\n",
    "  target_cluster = c[target]\n",
    "  for p in range(len(graph.nodes)):\n",
    "    if c[p] == target_cluster:\n",
    "        clustered.append(p)\n",
    "  clustered_graph = graph.subgraph(clustered)\n",
    "  print(\"Clustered graph: \" + str(clustered_graph))\n",
    "  #Remove nodes that are not connected\n",
    "  if(directed):\n",
    "    u = clustered_graph.to_undirected()\n",
    "    nodes = nx.node_connected_component(u, target)\n",
    "    clustered_graph = clustered_graph.subgraph(nodes)\n",
    "  else:\n",
    "    clustered_graph = nx.node_connected_component(clustered_graph, target)\n",
    "  print(\"Clustered graph's (weakly) connected component with target node: \" + str(clustered_graph))\n",
    "  return clustered_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Su4OrvLnwoT2"
   },
   "source": [
    "**Execution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CJAFcS7nK8zU"
   },
   "outputs": [],
   "source": [
    "#Author: Savoia Emanuele\n",
    "\n",
    "#convert graph embeddings into numpy arrays to be clustered\n",
    "graph_arrays = []\n",
    "\n",
    "for i in range(len(models)):\n",
    "  vectors = []\n",
    "  for p in range(graphs[i].number_of_nodes()):\n",
    "      vectors.append(models[i].wv[p])\n",
    "  graph_arrays.append(np.array(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AtSS-w2rJQhA"
   },
   "outputs": [],
   "source": [
    "#Author: Savoia Emanuele\n",
    "\n",
    "#Cluster, save execution data and plot\n",
    "best_c_sampled_arr = []\n",
    "best_c_unsampled_arr = []\n",
    "scores_sampled_arr = []\n",
    "scores_unsampled_arr = []\n",
    "k_tried_sampled_arr = []\n",
    "k_tried_unsampled_arr = []\n",
    "\n",
    "for points in graph_arrays:\n",
    "  best_c_sampled, scores_sampled, k_tried_sampled = sklearn_kmeans_find_k(points)\n",
    "\n",
    "  best_c_unsampled, scores_unsampled, k_tried_unsampled = sklearn_kmeans_find_k(points, False)\n",
    "\n",
    "  best_c_sampled_arr.append(best_c_sampled)\n",
    "  best_c_unsampled_arr.append(best_c_unsampled)\n",
    "  scores_sampled_arr.append(scores_sampled)\n",
    "  scores_unsampled_arr.append(scores_unsampled)\n",
    "  k_tried_sampled_arr.append(k_tried_sampled)\n",
    "  k_tried_unsampled_arr.append(k_tried_unsampled)\n",
    "\n",
    "for i in range(len(graph_arrays)):\n",
    "  plot_save_scores(scores_sampled_arr[i], k_tried_sampled_arr[i], files[i] + \"_sampled\")\n",
    "  plot_save_scores(scores_unsampled_arr[i], k_tried_unsampled_arr[i], files[i] + \"_unsampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mRM339ARdft"
   },
   "outputs": [],
   "source": [
    "#Author: Savoia Emanuele\n",
    "\n",
    "targets = []\n",
    "clustered_graphs = []\n",
    "\n",
    "for i in range(len(graphs)):\n",
    "  #Target node chosen at random\n",
    "  target = random.randrange(graphs[i].number_of_nodes())\n",
    "  print(\"Target node is \" + str(target) + \"for graph \" + str(i))\n",
    "  targets.append(target)\n",
    "  targets.append(target)\n",
    "  clustered_graphs.append(reduce_graph_to_cluster_subgraph(graphs[i], directed[i], best_c_sampled_arr[i], target))\n",
    "  clustered_graphs.append(reduce_graph_to_cluster_subgraph(graphs[i], directed[i], best_c_unsampled_arr[i], target))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPHd-FAcRdfu"
   },
   "source": [
    "Valutazione nodi (usare clustered_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXji37fVRdfv"
   },
   "outputs": [],
   "source": [
    "#Author:Vendramin Riccardo\n",
    "# FUNCTIONS DEFINITION\n",
    "\n",
    "# Neighbor\n",
    "def n(v, edges):\n",
    "    neighbors = set()\n",
    "    for edge in edges:\n",
    "        if v in edge:\n",
    "            neighbors.update(edge)\n",
    "\n",
    "    neighbors.discard(v)\n",
    "\n",
    "    return list(neighbors)\n",
    "\n",
    "# Generate undirected with edge = both arcs\n",
    "def create_undirected_graph_from_directed(directed_graph):\n",
    "    undirected_graph = nx.Graph()\n",
    "\n",
    "    for edge in directed_graph.edges():\n",
    "        if directed_graph.has_edge(edge[0], edge[1]) and directed_graph.has_edge(edge[1], edge[0]):\n",
    "            undirected_graph.add_edge(edge[0], edge[1])\n",
    "\n",
    "    return undirected_graph\n",
    "\n",
    "# Bron-Kerbosch algorithm with pivot\n",
    "def BronKerbosch(R, P, X, edges, cliques):\n",
    "    if not P and not X:\n",
    "        # P and X are both empty, report R as a maximal clique\n",
    "        cliques.append(R)\n",
    "        return\n",
    "\n",
    "    # Choose a pivot vertex u in P ⋃ X\n",
    "    pivot = (set(P) | set(X)).pop()\n",
    "\n",
    "    for v in set(P) - set(n(pivot, edges)):\n",
    "        # Recursively explore the neighborhood of v\n",
    "        BronKerbosch(R + [v], list(set(P) & set(n(v, edges))), list(set(X) & set(n(v, edges))), edges, cliques)\n",
    "\n",
    "        # Remove v from P and add it to X\n",
    "        P.remove(v)\n",
    "        X.append(v)\n",
    "\n",
    "# Max clique\n",
    "def maxClique(cliques):\n",
    "    return max(cliques, key=len, default=[])\n",
    "\n",
    "# Find cliques of target node\n",
    "def nodeCliques(all_cliques, selected_node):\n",
    "    node_cliques = []\n",
    "    for clique in all_cliques:\n",
    "        if selected_node in clique:\n",
    "            node_cliques.append(clique)\n",
    "    return node_cliques\n",
    "\n",
    "# Compute clustering coefficient for nodes\n",
    "def runNodeCC(graph):\n",
    "    node_cluster_coefs = nx.clustering(graph)\n",
    "\n",
    "    return node_cluster_coefs\n",
    "\n",
    "# Find clique with best cc\n",
    "def bestClique(node_cliques, node_cluster_coefs):\n",
    "    max_cc = 0\n",
    "    best_clique = []\n",
    "    for clique in node_cliques:\n",
    "        avg_cc = 0;\n",
    "        for node in clique:\n",
    "            avg_cc += node_cluster_coefs[node]\n",
    "\n",
    "        print(\"clique:  \" + str(clique))\n",
    "        print(\"clique cc:  \" + str(avg_cc/len(clique)))\n",
    "\n",
    "        if avg_cc/len(clique) > max_cc:\n",
    "            best_clique = clique\n",
    "    return best_clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMlb6EQpRdfw"
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_solution(clustered_graph):\n",
    "  # Numero di nodi da rimuovere ad ogni iterazione\n",
    "  n_nodes_to_remove = int(random.uniform(1,10)/100 * len(clustered_graph.nodes))\n",
    "\n",
    "  # Numero totale di iterazioni\n",
    "  n_iterations = 100\n",
    "\n",
    "  # Copia del grafo iniziale\n",
    "  graph_to_modify = graph.copy()\n",
    "\n",
    "  #results\n",
    "  results = []\n",
    "\n",
    "  for iteration in range(n_iterations):\n",
    "      # Escludere il target\n",
    "      filtered_nodes = [element for element in list(graph_to_modify.nodes()) if element != selected_node]\n",
    "\n",
    "      # Rimuovi n nodi casuali dal grafo\n",
    "      nodes_to_remove = random.sample(filtered_nodes, n_nodes_to_remove)\n",
    "      updated_graph = graph_to_modify.copy()\n",
    "      updated_graph.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "      # Stampa o elabora i risultati desiderati\n",
    "      print(f\"Iteration {iteration + 1}: Removed nodes {nodes_to_remove}\")\n",
    "\n",
    "      all_cliques = []\n",
    "      updated_graph = create_undirected_graph_from_directed(updated_graph)\n",
    "      BronKerbosch([], list(updated_graph.nodes), [], updated_graph.edges, all_cliques)\n",
    "      node_cliques = nodeCliques(all_cliques, selected_node)\n",
    "      print(\"Cliques nodo:\")\n",
    "      print(node_cliques)\n",
    "      best_clique = bestClique(node_cliques, runNodeCC(updated_graph))\n",
    "      print(\"Best clique\")\n",
    "      print(best_clique)\n",
    "      results.append(best_clique)\n",
    "\n",
    "      # Aggiorna il grafo originale per la prossima iterazione\n",
    "      #graph_to_modify = updated_graph.copy()\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0zzb1rdBZ1R"
   },
   "outputs": [],
   "source": [
    "#plot results\n",
    "\n",
    "def generate_histogram(array_of_arrays, title, found):\n",
    "    # Convert inner arrays to tuples and use Counter\n",
    "    element_counts = Counter(tuple(inner_array) for inner_array in array_of_arrays)\n",
    "\n",
    "    # Extract elements and their counts\n",
    "    elements = list(element_counts.keys())\n",
    "    counts = list(element_counts.values())\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.bar(range(len(elements)), counts, align='center')\n",
    "    plt.xticks(range(len(elements)), elements)\n",
    "    plt.xlabel('Cliques')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram obtained, out result: ' + str(found))\n",
    "\n",
    "    # Annotate each bar with its count\n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center', va='bottom')\n",
    "\n",
    "    plt.savefig(plots_dir + title + '.png')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3XVvQwdj8GT"
   },
   "outputs": [],
   "source": [
    "#Author:Vendramin Riccardo\n",
    "\n",
    "# Find target's best clique\n",
    "for i in range(len(clustered_graphs)):\n",
    "  all_cliques = []\n",
    "  selected_node = 12\n",
    "  graph = create_undirected_graph_from_directed(clustered_graphs[i])\n",
    "  BronKerbosch([], list(graph.nodes), [], graph.edges, all_cliques)\n",
    "  #print(all_cliques)\n",
    "  node_cliques = nodeCliques(all_cliques, selected_node)\n",
    "  print(\"Cliques nodo:\")\n",
    "  print(node_cliques)\n",
    "  print(\"Best clique\")\n",
    "  best_cl = bestClique(node_cliques, runNodeCC(graph))\n",
    "  print(best_cl)\n",
    "  results = test_solution(graph)\n",
    "  end = \"\"\n",
    "  if i%2 == 0:\n",
    "    end = \"sampled\"\n",
    "  else:\n",
    "    end = \"unsampled\"\n",
    "  generate_histogram(results, \"Result-histogram-\" + files[int(i/2)] + \"-\", best_cl)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
