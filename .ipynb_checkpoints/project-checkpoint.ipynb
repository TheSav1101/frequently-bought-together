{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqVzrDURRdfh"
   },
   "source": [
    "Frequently Bought Toghether Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use only if on Colab and there is a _COLAB folder in your Google Drive with necessary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JerKv_BSSvXx",
    "outputId": "fe736be9-f69e-4adf-e0a9-a816b2cb80e9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "import os\n",
    "os.chdir(\"drive/MyDrive/_COLAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWZstf_yRdfm"
   },
   "source": [
    "Initialize graphs etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxvzxjEORdfn"
   },
   "outputs": [],
   "source": [
    "#Author: Everyone\n",
    "import random\n",
    "import networkx as nx\n",
    "import node2vec\n",
    "from gensim.models import Word2Vec\n",
    "import os.path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import time\n",
    "import math\n",
    "\n",
    "#Nodo target\n",
    "target = -1 ##modificato in seguito a random\n",
    "\n",
    "#Grafo completo FBT\n",
    "full_graph = nx.Graph()\n",
    "\n",
    "#Grafo cluster selezionato\n",
    "clustered_graph = nx.Graph()\n",
    "\n",
    "#File di lettura\n",
    "file_ = \"Amazon0302\"\n",
    "file_name = file_ + \".txt\"\n",
    "#file_name = \"grafo_esempio.txt\"\n",
    "\n",
    "#Grafo directed se True o uniderected se False\n",
    "directed = True\n",
    "\n",
    "#embedding hyperparameters\n",
    "#default = 1, 1, 10, 80\n",
    "p=1\n",
    "q=1\n",
    "num_walks=10\n",
    "walk_length=80\n",
    "\n",
    "saved = False\n",
    "if(os.path.isfile(file_ + \".model\")):\n",
    "  saved = True\n",
    "\n",
    "### LOAD GRAPH ###\n",
    "print(\"loading graph \" + file_name)\n",
    "\n",
    "if directed:\n",
    "    ##genera il grafo directed utilizzando nx.DiGraph\n",
    "    full_graph = nx.read_edgelist(file_name, nodetype=int, create_using=nx.DiGraph)\n",
    "\n",
    "else:\n",
    "    ##genera il grafo undirected utilizzando nx.Graph\n",
    "    full_graph = nx.read_edgelist(file_name)\n",
    "\n",
    "nx.set_edge_attributes(full_graph, 1, name='weight')\n",
    "\n",
    "print(full_graph)\n",
    "\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvwyMMaHRdfq"
   },
   "source": [
    "Embedding using stanford's node2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANAuvlt2Rdfr",
    "outputId": "4e376c59-8012-4fa4-f236-6d4565f14f6f"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "if(saved):\n",
    "  print(\"Saved model found, loading file...\")\n",
    "  model = Word2Vec.load(file_ + \".model\")\n",
    "else:\n",
    "  print(\"No saved model found, generating embedding...\")\n",
    "  G = node2vec.Graph(full_graph, directed, p, q)\n",
    "  G.preprocess_transition_probs()\n",
    "  walks = G.simulate_walks(num_walks, walk_length)\n",
    "  walks = [list(map(str, walk)) for walk in walks]\n",
    "  model = Word2Vec(walks, window=10, min_count=0, sg=1, workers=100)\n",
    "  model.save(file_ + \".model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vB73xH0SRdfr"
   },
   "source": [
    "Kmeans and sampled kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aqfoVs_jRdfs",
    "outputId": "d98de8be-201b-43fc-e7a2-eb8280b6ca3e"
   },
   "outputs": [],
   "source": [
    "#Author:Savoia Emanuele\n",
    "vectors = []\n",
    "#initialize vector of points to be used in Kmeans\n",
    "for p in range(full_graph.number_of_nodes()):\n",
    "    vectors.append(model.wv[p])\n",
    "points = np.array(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Savoia Emanuele\n",
    "\n",
    "##Min tolerated sh score to proceed is: [best_score - max_error]\n",
    "max_error = 0.025\n",
    "\n",
    "#use sklearn implementation of kmeans++ combined with silhouette score to find best k and clustering\n",
    "# if sampled is True use MiniBatchKMeans instead of kmeans\n",
    "def sklearn_kmeans_find_k(points, sampled=True):\n",
    "  start_time = time.time()\n",
    "  #best clustering until this iteration\n",
    "  best_clustering = []\n",
    "  #array of scores used for plot\n",
    "  scores = []\n",
    "  #array of K associated with scores, used for plot\n",
    "  k_tried = []\n",
    "  #best silhouette until now\n",
    "  best_score = -99999\n",
    "  #mnimum k value\n",
    "  min_k = int(math.sqrt(len(points)))*4\n",
    "  for k in range(min_k, len(points), 15):\n",
    "    print(\"trying kmeans with k = \" + str(k))\n",
    "    score = -1.0\n",
    "    clustering = []\n",
    "    if sampled:\n",
    "      #choose sample size based on k and vector size\n",
    "      sample_size = int(k*1.75)\n",
    "      if(sample_size < 1024 and len(points) >= 1024):\n",
    "        sample_size = 1024\n",
    "      elif(sample_size > len(points)):\n",
    "        sample_size = len(points)\n",
    "      #run kmeans++ with mini batches\n",
    "      kmeans = MiniBatchKMeans(n_clusters=k, init='k-means++', batch_size=sample_size, n_init='auto')\n",
    "      clustering = kmeans.fit_predict(points)      \n",
    "    else:\n",
    "      #run kmeans++\n",
    "      kmeans = KMeans(n_clusters=k, init='k-means++', n_init='auto')\n",
    "      clustering = kmeans.fit_predict(points)\n",
    "    #calculate silhouette from sample\n",
    "    score = silhouette_score(points, clustering, sample_size=min_k*10)\n",
    "    print(\"> Current silhouette score:   \" + str(score))\n",
    "    print(\"> Last best silhouette score: \" + str(best_score))\n",
    "    #update results and check if within parameters\n",
    "    if score >= best_score - max_error:\n",
    "      best_clustering = clustering\n",
    "      best_score = score\n",
    "      scores.append(score)\n",
    "      k_tried.append(k)\n",
    "    else:\n",
    "      print(\"Time since start: \" + str(time.time() - start_time))\n",
    "      return best_clustering, scores, k_tried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Savoia Emanuele\n",
    "best_c_sampled, scores_sampled, k_tried_sampled = sklearn_kmeans_find_k(points)\n",
    "print(best_c_sampled)\n",
    "best_c_unsampled, scores_unsampled, k_tried_unsampled = sklearn_kmeans_find_k(points, False)\n",
    "print(best_c_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Savoia Emanuele\n",
    "clustered_sampled = []\n",
    "clustered_unsampled = []\n",
    "\n",
    "#Nodo target\n",
    "target = random.randrange(full_graph.number_of_nodes())\n",
    "print(\"Target node is: \" + str(target))\n",
    "\n",
    "target_cluster_sampled = best_c_sampled[target]\n",
    "target_cluster_unsampled = best_c_unsampled[target]\n",
    "\n",
    "for p in range(len(points)):\n",
    "    if best_c_sampled[p] == target_cluster_sampled:\n",
    "        clustered_sampled.append(p)\n",
    "    if best_c_unsampled[p] == target_cluster_unsampled:\n",
    "        clustered_unsampled.append(p)\n",
    "\n",
    "clustered_graph_s = full_graph.subgraph(clustered_sampled)\n",
    "clustered_graph_u = full_graph.subgraph(clustered_unsampled)\n",
    "\n",
    "print(\"Clustered graph: \" + str(clustered_graph_s))\n",
    "#Remove nodes that are not connected\n",
    "if(directed):\n",
    "  u = clustered_graph_s.to_undirected()\n",
    "  nodes = nx.node_connected_component(u, target)\n",
    "  clustered_graph_s = clustered_graph_s.subgraph(nodes)\n",
    "else:\n",
    "  clustered_graph_s = nx.node_connected_component(clustered_graph_s, target)\n",
    "\n",
    "print(\"Clustered graph's (weakly) connected component with target node: \" + str(clustered_graph_s))\n",
    "\n",
    "print(\"Clustered graph unsampled: \" + str(clustered_graph_u))\n",
    "#Remove nodes that are not connected\n",
    "if(directed):\n",
    "  u = clustered_graph_u.to_undirected()\n",
    "  nodes = nx.node_connected_component(u, target)\n",
    "  clustered_graph_u = clustered_graph_u.subgraph(nodes)\n",
    "else:\n",
    "  clustered_graph_u = nx.node_connected_component(clustered_graph_u, target)\n",
    "\n",
    "print(\"Unsampled clustered graph's (weakly) connected component with target node: \" + str(clustered_graph_u))\n",
    "\n",
    "#########CHOOSE GRAPH WITH MORE NODES##############\n",
    "clustered_graph = clustered_graph_u\n",
    "if(len(clustered_graph_s.nodes) > len(clustered_graph_u.nodes)):\n",
    "  clustered_graph = clustered_graph_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPHd-FAcRdfu"
   },
   "source": [
    "Valutazione nodi (usare clustered_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXji37fVRdfv"
   },
   "outputs": [],
   "source": [
    "#Author:Vendramin Riccardo\n",
    "# FUNCTIONS DEFINITION\n",
    "\n",
    "# Neighbor\n",
    "def n(v, edges):\n",
    "    neighbors = set()\n",
    "    for edge in edges:\n",
    "        if v in edge:\n",
    "            neighbors.update(edge)\n",
    "\n",
    "    neighbors.discard(v)\n",
    "\n",
    "    return list(neighbors)\n",
    "\n",
    "# Generate undirected with edge = both arcs\n",
    "def create_undirected_graph_from_directed(directed_graph):\n",
    "    undirected_graph = nx.Graph()\n",
    "\n",
    "    for edge in directed_graph.edges():\n",
    "        if directed_graph.has_edge(edge[0], edge[1]) and directed_graph.has_edge(edge[1], edge[0]):\n",
    "            undirected_graph.add_edge(edge[0], edge[1])\n",
    "\n",
    "    return undirected_graph\n",
    "\n",
    "# Bron-Kerbosch algorithm with pivot\n",
    "def BronKerbosch(R, P, X, edges, cliques):\n",
    "    if not P and not X:\n",
    "        # P and X are both empty, report R as a maximal clique\n",
    "        cliques.append(R)\n",
    "        return\n",
    "\n",
    "    # Choose a pivot vertex u in P â‹ƒ X\n",
    "    pivot = (set(P) | set(X)).pop()\n",
    "\n",
    "    for v in set(P) - set(n(pivot, edges)):\n",
    "        # Recursively explore the neighborhood of v\n",
    "        BronKerbosch(R + [v], list(set(P) & set(n(v, edges))), list(set(X) & set(n(v, edges))), edges, cliques)\n",
    "\n",
    "        # Remove v from P and add it to X\n",
    "        P.remove(v)\n",
    "        X.append(v)\n",
    "\n",
    "# Max clique\n",
    "def maxClique(cliques):\n",
    "    return max(cliques, key=len, default=[])\n",
    "\n",
    "# Find cliques of target node\n",
    "def nodeCliques(all_cliques, selected_node):\n",
    "    node_cliques = []\n",
    "    for clique in all_cliques:\n",
    "        if selected_node in clique:\n",
    "            node_cliques.append(clique)\n",
    "    return node_cliques\n",
    "\n",
    "# Compute clustering coefficient for nodes\n",
    "def runNodeCC(graph):\n",
    "    node_cluster_coefs = nx.clustering(graph)\n",
    "        \n",
    "    return node_cluster_coefs\n",
    "\n",
    "# Find clique with best cc\n",
    "def bestClique(node_cliques, node_cluster_coefs):\n",
    "    max_cc = 0\n",
    "    best_clique = []\n",
    "    for clique in node_cliques:\n",
    "        avg_cc = 0;\n",
    "        for node in clique:\n",
    "            avg_cc += node_cluster_coefs[node]\n",
    "\n",
    "        print(\"clique:  \" + str(clique))\n",
    "        print(\"clique cc:  \" + str(avg_cc/len(clique)))\n",
    "        \n",
    "        if avg_cc/len(clique) > max_cc:\n",
    "            best_clique = clique\n",
    "    return best_clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYpmaXHJRdfw"
   },
   "outputs": [],
   "source": [
    "#Author:Vendramin Riccardo\n",
    "\n",
    "# Find target best clique\n",
    "all_cliques = []\n",
    "selected_node = 12\n",
    "clustered_graph = create_undirected_graph_from_directed(clustered_graph)\n",
    "BronKerbosch([], list(clustered_graph.nodes), [], clustered_graph.edges, all_cliques)\n",
    "#print(all_cliques)\n",
    "node_cliques = nodeCliques(all_cliques, selected_node)\n",
    "print(\"Cliques nodo:\")\n",
    "print(node_cliques)\n",
    "print(\"Best clique\")\n",
    "print(bestClique(node_cliques, runNodeCC(clustered_graph)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMlb6EQpRdfw"
   },
   "outputs": [],
   "source": [
    "#Tentativi con rimozioni casuali\n",
    "# Numero di nodi da rimuovere ad ogni iterazione\n",
    "n_nodes_to_remove = 10\n",
    "\n",
    "# Numero totale di iterazioni\n",
    "n_iterations = 100\n",
    "\n",
    "# Copia del grafo iniziale\n",
    "graph_to_modify = graph.copy()\n",
    "\n",
    "#results\n",
    "results = []\n",
    "\n",
    "for iteration in range(n_iterations):\n",
    "    # Escludere il target\n",
    "    filtered_nodes = [element for element in list(graph_to_modify.nodes()) if element != selected_node]\n",
    "    \n",
    "    # Rimuovi n nodi casuali dal grafo\n",
    "    nodes_to_remove = random.sample(filtered_nodes, n_nodes_to_remove)\n",
    "    updated_graph = graph_to_modify.copy()\n",
    "    updated_graph.remove_nodes_from(nodes_to_remove)\n",
    "\n",
    "    # Stampa o elabora i risultati desiderati\n",
    "    print(f\"Iteration {iteration + 1}: Removed nodes {nodes_to_remove}\")\n",
    "\n",
    "    all_cliques = []\n",
    "    updated_graph = create_undirected_graph_from_directed(updated_graph)\n",
    "    BronKerbosch([], list(updated_graph.nodes), [], updated_graph.edges, all_cliques)\n",
    "    node_cliques = nodeCliques(all_cliques, selected_node)\n",
    "    print(\"Cliques nodo:\")\n",
    "    print(node_cliques)\n",
    "    best_clique = bestClique(node_cliques, runNodeCC(updated_graph))\n",
    "    print(\"Best clique\")\n",
    "    print(best_clique)\n",
    "    results.append(best_clique)\n",
    "    \n",
    "    # Aggiorna il grafo originale per la prossima iterazione\n",
    "    #graph_to_modify = updated_graph.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author:Vendramin Riccardo\n",
    "# Plot results\n",
    "\n",
    "def generate_histogram(array_of_arrays):\n",
    "    # Convert inner arrays to tuples and use Counter\n",
    "    element_counts = Counter(tuple(inner_array) for inner_array in array_of_arrays)\n",
    "\n",
    "    # Extract elements and their counts\n",
    "    elements = list(element_counts.keys())\n",
    "    counts = list(element_counts.values())\n",
    "\n",
    "    # Plot the histogram\n",
    "    plt.bar(range(len(elements)), counts, align='center')\n",
    "    plt.xticks(range(len(elements)), elements)\n",
    "    plt.xlabel('Best clique')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Histogram of results obtained')\n",
    "    \n",
    "    # Annotate each bar with its count\n",
    "    for i, count in enumerate(counts):\n",
    "        plt.text(i, count + 0.1, str(count), ha='center', va='bottom')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "generate_histogram(results)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
